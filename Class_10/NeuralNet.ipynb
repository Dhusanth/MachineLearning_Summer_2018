{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READING DATA\n",
    "data = pd.read_csv('/Users/tanish/Downloads/DATA/data1.csv' , header = None)\n",
    "label = pd.read_csv('/Users/tanish/Downloads/DATA/label1.csv' , header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERTING DATA INTO ARRAY\n",
    "data_arr = np.asarray(data)\n",
    "label_arr = np.asarray(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 5)\n"
     ]
    }
   ],
   "source": [
    "#CONVERTING OUTPUT LABELS INTO ONE HOT MATRIX\n",
    "type_of_output = 5\n",
    "one_hot = np.eye(type_of_output)[label_arr][:,0,:]  \n",
    "print(one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 20)\n",
      "(2000, 20)\n",
      "(2000, 20)\n"
     ]
    }
   ],
   "source": [
    "#DATA SPLITING\n",
    "x_train , x_test , y_train , y_test = train_test_split(data_arr , one_hot , test_size = 0.2 , random_state = 1)\n",
    "x_val , x_test , y_val , y_test = train_test_split(x_test , y_test , test_size = 0.5 , random_state = 1)\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT FEATURES = 20\n",
    "#OUTPUT = 5\n",
    "#I AM MAKING A MODEL WITH ONLY ONE HIDDEN LAYER HAVING 10 NEURONS\n",
    "#HLN INDICATES HIDDEN LAYER NEURONS\n",
    "hln = 10\n",
    "\n",
    "#FUNCTION FOR INITIALSISING WEIGHTS & BIASES\n",
    "def init_wb(layer_neurons , next_layer_neurons):\n",
    "    wt = np.random.normal(0 , 1/ np.sqrt(layer_neurons) , (layer_neurons , next_layer_neurons))\n",
    "    bias = np.zeros((1 , next_layer_neurons))\n",
    "    return wt , bias\n",
    "\n",
    "\n",
    "#ACTIVATION FUNCTIONS =>\n",
    "\n",
    "#SIGMOID FUNCTION\n",
    "def sigmoid(a):\n",
    "    return 1/(1 + np.exp(-a))\n",
    "\n",
    "#RELU FUNCTION\n",
    "def relu(z):\n",
    "    return max(0,z)\n",
    "\n",
    "#TANH FUNCTION\n",
    "def tnh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "#SOFTMAX FUNCTION\n",
    "def softmax(z):\n",
    "    e_z=np.exp(z)\n",
    "    return e_z/np.sum(e_z,axis=1,keepdims = True)\n",
    "\n",
    "#FUNCTION FOR APPLYING WEIGHTS , BIASES & ACTIVATION\n",
    "def forward_pass(a0 , w1 , w2 , b1 , b2):\n",
    "    f1 = np.dot(a0 , w1) + b1\n",
    "    a1 = tnh(f1)\n",
    "    f2 = np.dot(a1 , w2) + b2\n",
    "    a2 = softmax(f2)\n",
    "    return a2 , a1\n",
    "\n",
    "#ACCURACY FUNCTION\n",
    "def accuracy(y,train_label,datasize):\n",
    "    maxInTrain = np.argmax(y , axis =1)\n",
    "    maxInLabel = np.argmax(train_label , axis = 1)\n",
    "    count =0\n",
    "    for l in range(datasize):\n",
    "        if(maxInTrain[l]==maxInLabel[l]):\n",
    "            count = count +1\n",
    "    return (count/datasize)*100\n",
    "\n",
    "#COST FUNCTION\n",
    "def cost_function(y_predicted , y_actual , datasize):\n",
    "    c = -np.sum(y_actual*np.log(y_predicted) + (1.0-y_actual)*np.log(1-y_predicted)) / (datasize)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.955190979828492\n",
      "Training Accuracy:  55.75\n",
      "Validation Accuracy:  56.49999999999999\n",
      "Testing Accuracy:  57.35\n",
      "\n",
      "1.7156024328771413\n",
      "Training Accuracy:  63.993750000000006\n",
      "Validation Accuracy:  64.9\n",
      "Testing Accuracy:  65.95\n",
      "\n",
      "1.5751571027890505\n",
      "Training Accuracy:  68.5625\n",
      "Validation Accuracy:  68.89999999999999\n",
      "Testing Accuracy:  69.85\n",
      "\n",
      "1.473173922921502\n",
      "Training Accuracy:  71.13125\n",
      "Validation Accuracy:  71.8\n",
      "Testing Accuracy:  72.7\n",
      "\n",
      "1.3951178449950552\n",
      "Training Accuracy:  72.80624999999999\n",
      "Validation Accuracy:  73.4\n",
      "Testing Accuracy:  74.4\n",
      "\n",
      "1.333698292241679\n",
      "Training Accuracy:  73.94375\n",
      "Validation Accuracy:  74.75\n",
      "Testing Accuracy:  76.05\n",
      "\n",
      "1.2839563303373438\n",
      "Training Accuracy:  74.94375\n",
      "Validation Accuracy:  75.9\n",
      "Testing Accuracy:  77.0\n",
      "\n",
      "1.242513621589409\n",
      "Training Accuracy:  75.94999999999999\n",
      "Validation Accuracy:  77.14999999999999\n",
      "Testing Accuracy:  77.85\n",
      "\n",
      "1.2070895264125039\n",
      "Training Accuracy:  76.67500000000001\n",
      "Validation Accuracy:  77.55\n",
      "Testing Accuracy:  78.5\n",
      "\n",
      "1.1761451929835678\n",
      "Training Accuracy:  77.275\n",
      "Validation Accuracy:  77.9\n",
      "Testing Accuracy:  79.25\n",
      "\n",
      "1.148637109064518\n",
      "Training Accuracy:  77.96875\n",
      "Validation Accuracy:  78.60000000000001\n",
      "Testing Accuracy:  79.35\n",
      "\n",
      "1.1238485952736632\n",
      "Training Accuracy:  78.55\n",
      "Validation Accuracy:  79.85\n",
      "Testing Accuracy:  79.65\n",
      "\n",
      "1.1012773102984874\n",
      "Training Accuracy:  78.9625\n",
      "Validation Accuracy:  80.10000000000001\n",
      "Testing Accuracy:  80.2\n",
      "\n",
      "1.0805621878813534\n",
      "Training Accuracy:  79.53125\n",
      "Validation Accuracy:  80.5\n",
      "Testing Accuracy:  80.30000000000001\n",
      "\n",
      "1.06143655241272\n",
      "Training Accuracy:  79.95\n",
      "Validation Accuracy:  80.80000000000001\n",
      "Testing Accuracy:  80.60000000000001\n",
      "\n",
      "1.043697565464786\n",
      "Training Accuracy:  80.375\n",
      "Validation Accuracy:  81.2\n",
      "Testing Accuracy:  80.9\n",
      "\n",
      "1.0271857052956592\n",
      "Training Accuracy:  80.71875\n",
      "Validation Accuracy:  81.8\n",
      "Testing Accuracy:  81.10000000000001\n",
      "\n",
      "1.011770806386884\n",
      "Training Accuracy:  81.04375\n",
      "Validation Accuracy:  82.15\n",
      "Testing Accuracy:  81.35\n",
      "\n",
      "0.997342775913435\n",
      "Training Accuracy:  81.3125\n",
      "Validation Accuracy:  82.5\n",
      "Testing Accuracy:  81.35\n",
      "\n",
      "0.9838057317363716\n",
      "Training Accuracy:  81.5875\n",
      "Validation Accuracy:  82.69999999999999\n",
      "Testing Accuracy:  81.69999999999999\n",
      "\n",
      "0.9710745198247331\n",
      "Training Accuracy:  81.84375\n",
      "Validation Accuracy:  82.89999999999999\n",
      "Testing Accuracy:  82.05\n",
      "\n",
      "0.9590727291939456\n",
      "Training Accuracy:  82.01875\n",
      "Validation Accuracy:  82.95\n",
      "Testing Accuracy:  82.35\n",
      "\n",
      "0.9477315427196726\n",
      "Training Accuracy:  82.1875\n",
      "Validation Accuracy:  83.2\n",
      "Testing Accuracy:  82.45\n",
      "\n",
      "0.9369890083182042\n",
      "Training Accuracy:  82.3125\n",
      "Validation Accuracy:  83.45\n",
      "Testing Accuracy:  82.6\n",
      "\n",
      "0.9267895155549813\n",
      "Training Accuracy:  82.53125\n",
      "Validation Accuracy:  83.65\n",
      "Testing Accuracy:  82.75\n",
      "\n",
      "0.9170833826079674\n",
      "Training Accuracy:  82.74375\n",
      "Validation Accuracy:  83.8\n",
      "Testing Accuracy:  82.85\n",
      "\n",
      "0.9078265092782293\n",
      "Training Accuracy:  82.89999999999999\n",
      "Validation Accuracy:  84.1\n",
      "Testing Accuracy:  83.1\n",
      "\n",
      "0.898980064623792\n",
      "Training Accuracy:  83.05\n",
      "Validation Accuracy:  84.3\n",
      "Testing Accuracy:  83.25\n",
      "\n",
      "0.8905101788836006\n",
      "Training Accuracy:  83.2375\n",
      "Validation Accuracy:  84.45\n",
      "Testing Accuracy:  83.45\n",
      "\n",
      "0.8823876114347777\n",
      "Training Accuracy:  83.4375\n",
      "Validation Accuracy:  84.6\n",
      "Testing Accuracy:  83.7\n",
      "\n",
      "0.8745873723561629\n",
      "Training Accuracy:  83.6\n",
      "Validation Accuracy:  84.7\n",
      "Testing Accuracy:  83.75\n",
      "\n",
      "0.8670882837938177\n",
      "Training Accuracy:  83.74374999999999\n",
      "Validation Accuracy:  84.95\n",
      "Testing Accuracy:  83.95\n",
      "\n",
      "0.8598724779317263\n",
      "Training Accuracy:  83.83125\n",
      "Validation Accuracy:  85.05\n",
      "Testing Accuracy:  84.1\n",
      "\n",
      "0.8529248408066903\n",
      "Training Accuracy:  83.96875\n",
      "Validation Accuracy:  85.25\n",
      "Testing Accuracy:  84.05\n",
      "\n",
      "0.846232424838091\n",
      "Training Accuracy:  84.16875\n",
      "Validation Accuracy:  85.15\n",
      "Testing Accuracy:  84.0\n",
      "\n",
      "0.8397838655711979\n",
      "Training Accuracy:  84.28750000000001\n",
      "Validation Accuracy:  85.25\n",
      "Testing Accuracy:  84.2\n",
      "\n",
      "0.8335688458112025\n",
      "Training Accuracy:  84.45625\n",
      "Validation Accuracy:  85.3\n",
      "Testing Accuracy:  84.3\n",
      "\n",
      "0.8275776488638976\n",
      "Training Accuracy:  84.65\n",
      "Validation Accuracy:  85.45\n",
      "Testing Accuracy:  84.25\n",
      "\n",
      "0.8218008304549376\n",
      "Training Accuracy:  84.7625\n",
      "Validation Accuracy:  85.55\n",
      "Testing Accuracy:  84.3\n",
      "\n",
      "0.8162290191638774\n",
      "Training Accuracy:  84.91875\n",
      "Validation Accuracy:  85.5\n",
      "Testing Accuracy:  84.65\n",
      "\n",
      "0.8108528344688579\n",
      "Training Accuracy:  85.0125\n",
      "Validation Accuracy:  85.55\n",
      "Testing Accuracy:  84.65\n",
      "\n",
      "0.8056628962237958\n",
      "Training Accuracy:  85.15\n",
      "Validation Accuracy:  85.6\n",
      "Testing Accuracy:  84.75\n",
      "\n",
      "0.8006498927653183\n",
      "Training Accuracy:  85.24374999999999\n",
      "Validation Accuracy:  85.9\n",
      "Testing Accuracy:  84.95\n",
      "\n",
      "0.7958046761604576\n",
      "Training Accuracy:  85.3375\n",
      "Validation Accuracy:  86.1\n",
      "Testing Accuracy:  84.95\n",
      "\n",
      "0.7911183593965417\n",
      "Training Accuracy:  85.45\n",
      "Validation Accuracy:  86.1\n",
      "Testing Accuracy:  85.1\n",
      "\n",
      "0.7865823984729188\n",
      "Training Accuracy:  85.50625\n",
      "Validation Accuracy:  86.15\n",
      "Testing Accuracy:  85.15\n",
      "\n",
      "0.7821886502755947\n",
      "Training Accuracy:  85.625\n",
      "Validation Accuracy:  86.35000000000001\n",
      "Testing Accuracy:  85.3\n",
      "\n",
      "0.7779294037427145\n",
      "Training Accuracy:  85.65625\n",
      "Validation Accuracy:  86.4\n",
      "Testing Accuracy:  85.25\n",
      "\n",
      "0.7737973867201409\n",
      "Training Accuracy:  85.75\n",
      "Validation Accuracy:  86.6\n",
      "Testing Accuracy:  85.39999999999999\n",
      "\n",
      "0.7697857539149713\n",
      "Training Accuracy:  85.81875\n",
      "Validation Accuracy:  86.65\n",
      "Testing Accuracy:  85.5\n",
      "\n",
      "0.7658880625503546\n",
      "Training Accuracy:  85.88125\n",
      "Validation Accuracy:  86.7\n",
      "Testing Accuracy:  85.6\n",
      "\n",
      "0.762098242018135\n",
      "Training Accuracy:  85.94375\n",
      "Validation Accuracy:  86.8\n",
      "Testing Accuracy:  85.85000000000001\n",
      "\n",
      "0.7584105625330587\n",
      "Training Accuracy:  86.01875\n",
      "Validation Accuracy:  86.9\n",
      "Testing Accuracy:  85.85000000000001\n",
      "\n",
      "0.7548196061011542\n",
      "Training Accuracy:  86.0375\n",
      "Validation Accuracy:  86.85000000000001\n",
      "Testing Accuracy:  86.0\n",
      "\n",
      "0.751320241518659\n",
      "Training Accuracy:  86.1\n",
      "Validation Accuracy:  87.0\n",
      "Testing Accuracy:  86.15\n",
      "\n",
      "0.7479076039065562\n",
      "Training Accuracy:  86.1375\n",
      "Validation Accuracy:  87.1\n",
      "Testing Accuracy:  86.1\n",
      "\n",
      "0.7445770785361785\n",
      "Training Accuracy:  86.2125\n",
      "Validation Accuracy:  87.15\n",
      "Testing Accuracy:  86.15\n",
      "\n",
      "0.741324288342281\n",
      "Training Accuracy:  86.25\n",
      "Validation Accuracy:  87.2\n",
      "Testing Accuracy:  86.3\n",
      "\n",
      "0.7381450844203398\n",
      "Training Accuracy:  86.31875\n",
      "Validation Accuracy:  87.25\n",
      "Testing Accuracy:  86.3\n",
      "\n",
      "0.7350355388402037\n",
      "Training Accuracy:  86.36875\n",
      "Validation Accuracy:  87.4\n",
      "Testing Accuracy:  86.45\n",
      "\n",
      "0.7319919391917333\n",
      "Training Accuracy:  86.425\n",
      "Validation Accuracy:  87.35000000000001\n",
      "Testing Accuracy:  86.5\n",
      "\n",
      "0.7290107843628847\n",
      "Training Accuracy:  86.47500000000001\n",
      "Validation Accuracy:  87.35000000000001\n",
      "Testing Accuracy:  86.55000000000001\n",
      "\n",
      "0.7260887811194031\n",
      "Training Accuracy:  86.55000000000001\n",
      "Validation Accuracy:  87.35000000000001\n",
      "Testing Accuracy:  86.7\n",
      "\n",
      "0.7232228411072621\n",
      "Training Accuracy:  86.63125000000001\n",
      "Validation Accuracy:  87.4\n",
      "Testing Accuracy:  86.75\n",
      "\n",
      "0.7204100779406979\n",
      "Training Accuracy:  86.675\n",
      "Validation Accuracy:  87.45\n",
      "Testing Accuracy:  86.85000000000001\n",
      "\n",
      "0.7176478040779299\n",
      "Training Accuracy:  86.7125\n",
      "Validation Accuracy:  87.5\n",
      "Testing Accuracy:  87.0\n",
      "\n",
      "0.7149335272292866\n",
      "Training Accuracy:  86.75\n",
      "Validation Accuracy:  87.5\n",
      "Testing Accuracy:  87.1\n",
      "\n",
      "0.7122649460914827\n",
      "Training Accuracy:  86.7875\n",
      "Validation Accuracy:  87.45\n",
      "Testing Accuracy:  87.1\n",
      "\n",
      "0.7096399452571674\n",
      "Training Accuracy:  86.825\n",
      "Validation Accuracy:  87.4\n",
      "Testing Accuracy:  87.25\n",
      "\n",
      "0.7070565892084394\n",
      "Training Accuracy:  86.825\n",
      "Validation Accuracy:  87.35000000000001\n",
      "Testing Accuracy:  87.25\n",
      "\n",
      "0.7045131153632749\n",
      "Training Accuracy:  86.875\n",
      "Validation Accuracy:  87.45\n",
      "Testing Accuracy:  87.2\n",
      "\n",
      "0.7020079262009509\n",
      "Training Accuracy:  86.91250000000001\n",
      "Validation Accuracy:  87.64999999999999\n",
      "Testing Accuracy:  87.3\n",
      "\n",
      "0.6995395805431097\n",
      "Training Accuracy:  86.95625\n",
      "Validation Accuracy:  87.64999999999999\n",
      "Testing Accuracy:  87.5\n",
      "\n",
      "0.697106784108527\n",
      "Training Accuracy:  87.0\n",
      "Validation Accuracy:  87.64999999999999\n",
      "Testing Accuracy:  87.5\n",
      "\n",
      "0.6947083794903772\n",
      "Training Accuracy:  86.99375\n",
      "Validation Accuracy:  87.7\n",
      "Testing Accuracy:  87.5\n",
      "\n",
      "0.692343335724346\n",
      "Training Accuracy:  87.03125\n",
      "Validation Accuracy:  87.64999999999999\n",
      "Testing Accuracy:  87.6\n",
      "\n",
      "0.6900107376247211\n",
      "Training Accuracy:  87.05625\n",
      "Validation Accuracy:  87.64999999999999\n",
      "Testing Accuracy:  87.64999999999999\n",
      "\n",
      "0.6877097750646797\n",
      "Training Accuracy:  87.08125\n",
      "Validation Accuracy:  87.75\n",
      "Testing Accuracy:  87.64999999999999\n",
      "\n",
      "0.6854397323679278\n",
      "Training Accuracy:  87.10625\n",
      "Validation Accuracy:  87.8\n",
      "Testing Accuracy:  87.7\n",
      "\n",
      "0.6831999779633431\n",
      "Training Accuracy:  87.18125\n",
      "Validation Accuracy:  87.8\n",
      "Testing Accuracy:  87.8\n",
      "\n",
      "0.6809899544341992\n",
      "Training Accuracy:  87.1875\n",
      "Validation Accuracy:  87.9\n",
      "Testing Accuracy:  87.85\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6788091690705907\n",
      "Training Accuracy:  87.23125\n",
      "Validation Accuracy:  87.9\n",
      "Testing Accuracy:  88.0\n",
      "\n",
      "0.6766571850094402\n",
      "Training Accuracy:  87.28125\n",
      "Validation Accuracy:  87.9\n",
      "Testing Accuracy:  88.0\n",
      "\n",
      "0.6745336130222986\n",
      "Training Accuracy:  87.29375\n",
      "Validation Accuracy:  88.05\n",
      "Testing Accuracy:  88.0\n",
      "\n",
      "0.6724381039881642\n",
      "Training Accuracy:  87.34375\n",
      "Validation Accuracy:  88.05\n",
      "Testing Accuracy:  87.94999999999999\n",
      "\n",
      "0.6703703420675745\n",
      "Training Accuracy:  87.43125\n",
      "Validation Accuracy:  88.1\n",
      "Testing Accuracy:  88.0\n",
      "\n",
      "0.66833003857589\n",
      "Training Accuracy:  87.48125\n",
      "Validation Accuracy:  88.1\n",
      "Testing Accuracy:  87.94999999999999\n",
      "\n",
      "0.6663169265383166\n",
      "Training Accuracy:  87.50625\n",
      "Validation Accuracy:  88.1\n",
      "Testing Accuracy:  87.94999999999999\n",
      "\n",
      "0.6643307558969611\n",
      "Training Accuracy:  87.5125\n",
      "Validation Accuracy:  88.14999999999999\n",
      "Testing Accuracy:  88.0\n",
      "\n",
      "0.6623712893310311\n",
      "Training Accuracy:  87.56875\n",
      "Validation Accuracy:  88.14999999999999\n",
      "Testing Accuracy:  88.0\n",
      "\n",
      "0.660438298644991\n",
      "Training Accuracy:  87.6375\n",
      "Validation Accuracy:  88.2\n",
      "Testing Accuracy:  88.0\n",
      "\n",
      "0.6585315616757833\n",
      "Training Accuracy:  87.6625\n",
      "Validation Accuracy:  88.25\n",
      "Testing Accuracy:  88.05\n",
      "\n",
      "0.6566508596687485\n",
      "Training Accuracy:  87.7125\n",
      "Validation Accuracy:  88.2\n",
      "Testing Accuracy:  88.1\n",
      "\n",
      "0.654795975072247\n",
      "Training Accuracy:  87.74374999999999\n",
      "Validation Accuracy:  88.35\n",
      "Testing Accuracy:  88.1\n",
      "\n",
      "0.6529666897028079\n",
      "Training Accuracy:  87.74374999999999\n",
      "Validation Accuracy:  88.4\n",
      "Testing Accuracy:  88.05\n",
      "\n",
      "0.651162783235507\n",
      "Training Accuracy:  87.775\n",
      "Validation Accuracy:  88.55\n",
      "Testing Accuracy:  88.1\n",
      "\n",
      "0.6493840319779126\n",
      "Training Accuracy:  87.8625\n",
      "Validation Accuracy:  88.55\n",
      "Testing Accuracy:  88.2\n",
      "\n",
      "0.647630207889989\n",
      "Training Accuracy:  87.9\n",
      "Validation Accuracy:  88.55\n",
      "Testing Accuracy:  88.25\n",
      "\n",
      "0.6459010778166321\n",
      "Training Accuracy:  87.9375\n",
      "Validation Accuracy:  88.6\n",
      "Testing Accuracy:  88.3\n",
      "\n",
      "0.64419640290377\n",
      "Training Accuracy:  87.95625\n",
      "Validation Accuracy:  88.64999999999999\n",
      "Testing Accuracy:  88.35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NEURAL MAIN()\n",
    "\n",
    "#initialising weights & biases\n",
    "w1 , b1 = init_wb(20 , hln)\n",
    "w2 , b2 = init_wb(hln , 5)\n",
    "\n",
    "#defining learning rate\n",
    "lr = 0.0001\n",
    "\n",
    "#batch size\n",
    "batch_size = 1000\n",
    "\n",
    "for j in range(100):\n",
    "    for i in range(16):\n",
    "        a0 = x_train[i*batch_size:(i+1)*batch_size,:]\n",
    "        target = y_train[batch_size*i:batch_size*(i+1),:]\n",
    "        \n",
    "        y , a1 = forward_pass(a0,w1,w2,b1,b2)\n",
    "        \n",
    "        #BACK PROPAGATION\n",
    "        del_2 = y-target\n",
    "        del_1 = np.dot(del_2,w2.T)*(1.0-(a1**2))\n",
    "            \n",
    "        dC_dW2 = np.dot(a1.T,del_2)\n",
    "        dC_dW1 = np.dot(a0.T,del_1)\n",
    "            \n",
    "        dC_dB2 = np.sum(del_2,axis=0)\n",
    "        dC_dB1 = np.sum(del_1,axis=0)\n",
    "         \n",
    "        #UPDATING THE VALUES OF WEIGHTS & BIASES    \n",
    "        w2 = w2 - (lr*dC_dW2)\n",
    "        w1 = w1 - (lr*dC_dW1)\n",
    "        b2 = b2 - (lr*dC_dB2)\n",
    "        b1 = b1 - (lr*dC_dB1)\n",
    "        \n",
    "    y_pr,_ = forward_pass(x_train,w1,w2,b1,b2)\n",
    "    cost1 = cost_function(y_pr , y_train , 16000)\n",
    "    print(cost1)\n",
    "    acc = accuracy(y_pr , y_train , 16000)\n",
    "    print(\"Training Accuracy: \", acc)\n",
    "        \n",
    "    y_validate,_ =forward_pass(x_val,w1,w2,b1,b2)\n",
    "    cost2 = cost_function(y_validate , y_val , 2000)\n",
    "    acc_val = accuracy(y_validate , y_val , 2000)\n",
    "    print(\"Validation Accuracy: \" , acc_val)\n",
    "        \n",
    "    y_testing,_ =forward_pass(x_test,w1,w2,b1,b2) \n",
    "    cost3 = cost_function(y_testing , y_test , 2000)\n",
    "    acc_test = accuracy(y_testing , y_test , 2000)\n",
    "    print(\"Testing Accuracy: \", acc_test)\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
